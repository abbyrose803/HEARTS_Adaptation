{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d316f71",
   "metadata": {},
   "source": [
    "# Hate Speech Detection - HEARTS to Davidson 2017 ‚Äì Model Adaptation & Evaluation Notebook\n",
    "\n",
    "## Overview\n",
    "This notebook adapts a pre-trained ALBERT text-classification model (after attempting to train it on the GOV.UK dataset) to the **Davidson et al. (2017) Hate Speech Dataset**.  \n",
    "\n",
    "The goal is to evaluate whether a stereotype-detection model can be successfully **repurposed and fine-tuned for hate-speech detection** within a socially critical Twitter context.\n",
    "\n",
    "It is reproducible and involves markdown alongside to explain findings and the process of this project - to compliment the presentation and poster.\n",
    "\n",
    "## Objectives\n",
    "- Reproduce and adapt the HEARTS MGSD baseline model\n",
    "- Fine-tune the model on the Davidson hate-speech dataset\n",
    "- Evaluate performance using accuracy, macro-F1, confusion matrix, and bootstrap confidence intervals\n",
    "- Conduct systematic **failure case analysis**\n",
    "- Propose targeted future improvements\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "1. **Environment Setup**\n",
    "   - Imports, seed setting, and library configuration\n",
    "\n",
    "2. **Dataset Loading & Pre-processing**\n",
    "   - Train/validation split\n",
    "   - Tokenisation and label mapping\n",
    "\n",
    "3. **Model Loading & Fine-Tuning**\n",
    "   - ALBERT model configuration\n",
    "   - Training arguments and optimisation\n",
    "\n",
    "4. **Evaluation Metrics**\n",
    "   - Accuracy\n",
    "   - Macro-F1\n",
    "   - Classification report\n",
    "   - Confusion matrix\n",
    "\n",
    "5. **Bootstrap Significance Testing**\n",
    "   - Confidence intervals for accuracy and macro-F1\n",
    "   - Stability analysis\n",
    "\n",
    "6. **Failure Case Analysis**\n",
    "   - False negatives (hate speech ‚Üí offensive)\n",
    "   - False positives (neutral ‚Üí offensive)\n",
    "   - High-confidence misclassifications\n",
    "   - Implicit / coded hate speech cases\n",
    "\n",
    "7. **Discussion & Future Improvements**\n",
    "   - Class imbalance effects\n",
    "   - Context and pragmatic limitations\n",
    "   - Fairness-aware and target-aware modelling proposals\n",
    "\n",
    "---\n",
    "\n",
    "## Reproducibility\n",
    "- Random seeds are fixed.\n",
    "- Dataset paths must be updated to local directories.\n",
    "- Model checkpoints are loaded from `/albert_hatespeech/best_model` (adjust if needed).\n",
    "\n",
    "## Expected Output\n",
    "- Validation metrics (Accuracy & Macro-F1)\n",
    "- Confusion matrix visualisation\n",
    "- Bootstrap confidence intervals\n",
    "- Error tables and qualitative failure examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e0db5e",
   "metadata": {},
   "source": [
    "### Original trial on GOV.UK\n",
    "\n",
    "- This can be found in the github, it has not been cleaned or made reproducible, as this was an unsuccesful attempt. It has been left in to show iteration and progress of this project (As adviced by Tigi).\n",
    "\n",
    "- I originally trained on a GOV.UK job adverts dataset, which collapsed due to the dataset exhibiting long sentences, with 30-50 tokens and very low linguistic variability and no abusive or profane language which led to overfitting causing the model to fail.\n",
    "\n",
    "\n",
    "- I selected the new context of detecting online hate speech‚Äîspecifically on Twitter in the United States‚Äîbecause the U.S. consistently reports high volumes of harmful, abusive, and polarising online content. Compared with GOV.UK job adverts, which were relatively formal, structured, and low-variance, Twitter presents a linguistically diverse, noisy, and high-risk environment where effective hate-speech detection has direct social impact.\n",
    "\n",
    "By adapting the MGSD ALBERT model to the Davidson et al. (2017) dataset and evaluating it through the HEARTS pipeline, this project assesses whether the original stereotype-detection model can be plausibly repurposed, successfully fine-tuned, and scaled to a more socially critical domain. Using HEARTS is appropriate here because HEARTS was designed specifically for text-based social bias, fairness, and sensitive-content detection‚Äîmaking it conceptually closer to hate-speech detection than GOV.UK adverts.\n",
    "\n",
    "#### This shift in context therefore serves two purposes:\n",
    "\n",
    "Practical alignment: The model is tested on a dataset whose linguistic style, label structure, and social stakes more closely resemble real-world harmful language detection tasks.\n",
    "\n",
    "Scalability assessment: It demonstrates whether a model originally developed for stereotype detection can generalise to adjacent applications such as online hate-speech mitigation‚Äîsupporting SDG 10 (Reduced Inequalities), SDG 16 (Peace, Justice and Strong Institutions) and SDG 5 (Gender Equality). \n",
    "\n",
    "Overall, applying the HEARTS evaluation workflow to the Davidson dataset provides a realistic indication of this model‚Äôs feasibility, robustness, and potential value within broader online safety, content moderation, and humanitarian AI settings.\n",
    "\n",
    "#### This Dataset was appropriate as it: \n",
    "- (1) Exhibits a large annotated corpus (24k) ideal for fine-tuning transformer models without overfitting. \n",
    "- (2) Reflects real-world linguistic challenges of social media, suitable for real-world applications.\n",
    "- (3) Widely used and benchmarked allowing for reproducibility.\n",
    "- (4) It offers 3 label classifications, that map directly onto a 3-class ALBERT model.\n",
    "- (5) It‚Äôs ethically sourced, from public tweets, no personal user information, transparent annotation and peer-reviewed. \n",
    "\n",
    "#### Dataset Limitations include: \n",
    "\n",
    "- (1) Imbalance: Hate speech is extremely underrepresented (~5%). \n",
    "- (2) Ambiguity: Many tweets contain sarcasm, coded language, or lack context.\n",
    "- (3) Racial slur ambiguity: slurs are automatically classified as offensive, but this can depend on context ‚Äî difficult for models. (3) Dataset is from 2017: Language, platform norms, and hate speech have evolved since then.\n",
    "- (4) No demographic metadata: cannot measure fairness across targeted groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66de5f6",
   "metadata": {},
   "source": [
    "huggingface link: https://huggingface.co/datasets/hate_speech_offensive \n",
    "data cvc: https://raw.githubusercontent.com/t-davidson/hate-speech-and-offensive-language/master/data/labeled_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b4cadf",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e2aea34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import random, numpy as np, torch\n",
    "from transformers import set_seed\n",
    "\n",
    "# ---- Paths ----\n",
    "PROJECT_ROOT = Path(\".\")\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"outputs\"\n",
    "MODEL_DIR = OUTPUT_DIR / \"models\" / \"albert_hatespeech\"\n",
    "MODEL_PATH = MODEL_DIR / \"best_model\"\n",
    "\n",
    "DATA_DIR.mkdir(exist_ok=True, parents=True)\n",
    "MODEL_DIR.mkdir(exist_ok=True, parents=True)\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ---- Reproducibility ----\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "set_seed(SEED)\n",
    "\n",
    "# ---- Control ----\n",
    "SKIP_TRAINING = True   # <‚Äî IMPORTANT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdfd7381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b08d3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.41.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.41.2)\n",
      "Requirement already satisfied: accelerate==0.30.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.30.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.41.2) (3.20.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.41.2) (0.36.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.41.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.41.2) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.41.2) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.41.2) (2026.1.15)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.41.2) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.41.2) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.41.2) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.41.2) (4.67.1)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.30.1) (7.2.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate==0.30.1) (2.6.0+cu124)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (2026.1.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (4.15.0)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.1) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.1) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.1) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.1) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.1) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.1) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.1) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.1) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.1) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.1) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.1) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.1) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30.1) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.30.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.30.1) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.41.2) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.41.2) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.41.2) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.41.2) (2026.1.4)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install transformers==4.41.2 accelerate==0.30.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20d482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import (\n",
    "    AlbertTokenizer,\n",
    "    AlbertForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33adc671",
   "metadata": {},
   "source": [
    "### Dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c347dc",
   "metadata": {},
   "source": [
    "#### Adapted an existing hate-speech dataset for compatibility with HEARTS \n",
    "\n",
    "The Davidson et al. dataset differs structurally from HEARTS‚Äô original stereotype-assessment format. Thus, I implemented the following preprocessing steps (1) tokenisation, (2) label mapping, (3) attention mask generation) to convert the dataset into a format suitable for ALBERT sequence classification. This allowed seamless evaluation and fine-tuning within the HEARTS framework‚Äîwithout modifying the dataset itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbfdcfb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/t-davidson/hate-speech-and-offensive-language/master/data/labeled_data.csv\"\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41cd17df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   24783 non-null  object\n",
      " 1   class   24783 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 387.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  class\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...      2\n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...      1\n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...      1\n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...      1\n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop useless index\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "# Keep only text + class\n",
    "df = df[[\"tweet\", \"class\"]]\n",
    "\n",
    "df.info()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "523aa6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24783.000000\n",
       "mean        85.436065\n",
       "std         41.548238\n",
       "min          5.000000\n",
       "25%         52.000000\n",
       "50%         81.000000\n",
       "75%        119.000000\n",
       "max        754.000000\n",
       "Name: tweet, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tweet\"].str.len().describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17a06588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1    0.774321\n",
       "2    0.167978\n",
       "0    0.057701\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"class\"].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e59fe4",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e1a1d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19826, 4957)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"class\"]\n",
    ")\n",
    "\n",
    "len(train_df), len(val_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02565131",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ff00b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5f7b530c9049f598b58d6c77247645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23120c942c0140c79024ac5c21169f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f4efc1b7bf4c8b85e22d3f41847827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe80c6e84f04ea584f4a50e73ceef14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AlbertTokenizerFast\n",
    "\n",
    "MODEL_NAME = \"albert-base-v2\"\n",
    "tokenizer = AlbertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "MAX_LEN = 128  # tweets are short\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e466e2",
   "metadata": {},
   "source": [
    "### Ablation 1: To prevent unnecessary padding and improve efficiency, I reduced the maximum sequence length to: MAX_LEN = 128.\n",
    "I retuned the tokenizer and maximum sequence length for short-form text: HEARTS contains long paragraph-based stereotype statements, whereas the Davidson dataset consists of short tweets (average ~85 characters). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21f09f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch dataset for Hate-Speech/Offensive-Language dataset.\n",
    "    Compatible with HuggingFace Trainer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, tokenizer, max_length):\n",
    "        self.texts = df[\"tweet\"].tolist()\n",
    "        self.labels = df[\"class\"].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = int(self.labels[idx])\n",
    "\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length\n",
    "        )\n",
    "\n",
    "        item = {k: torch.tensor(v) for k, v in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(label)\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c77f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TweetsDataset(train_df, tokenizer, MAX_LEN)\n",
    "val_dataset   = TweetsDataset(val_df, tokenizer, MAX_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e439f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3802956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Model already trained ‚Äî skipping training.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from transformers import AlbertForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "OUTPUT_DIR = \"./albert_hatespeech\"\n",
    "\n",
    "# Check if model already trained\n",
    "if os.path.exists(f\"{OUTPUT_DIR}/trainer_state.json\"):\n",
    "    print(\"‚úî Model already trained ‚Äî skipping training.\")\n",
    "    MODEL_ALREADY_TRAINED = True\n",
    "else:\n",
    "    MODEL_ALREADY_TRAINED = False\n",
    "    print(\"üîß No saved model found ‚Äî ready to train.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "953c722e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded saved model.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import AlbertForSequenceClassification\n",
    "\n",
    "BEST_DIR = \"./albert_hatespeech/best_model\"\n",
    "\n",
    "if os.path.exists(BEST_DIR):\n",
    "    model = AlbertForSequenceClassification.from_pretrained(BEST_DIR)\n",
    "    print(\"Loaded saved model.\")\n",
    "else:\n",
    "    print(\"Model folder not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e094268e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded saved model from best_model.\n",
      "Trainer ready.\n"
     ]
    }
   ],
   "source": [
    "# ---- Metrics ----\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n",
    "        \"f1_weighted\": f1_score(labels, preds, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "# Load model\n",
    "import os\n",
    "\n",
    "BEST_DIR = \"./albert_hatespeech/best_model\"\n",
    "MODEL_EXISTS = os.path.exists(os.path.join(BEST_DIR, \"config.json\"))\n",
    "\n",
    "if MODEL_EXISTS:\n",
    "    model = AlbertForSequenceClassification.from_pretrained(BEST_DIR)\n",
    "    print(\"Loaded saved model from best_model.\")\n",
    "else:\n",
    "    model = AlbertForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=3\n",
    "    )\n",
    "    print(\"No saved model found ‚Äî loading fresh (would need training to create one).\")\n",
    "\n",
    "\n",
    "\n",
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./albert_hatespeech\",\n",
    "    num_train_epochs=3,\n",
    "\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "\n",
    "    report_to=\"none\"        # prevents wandb/tensorboard errors\n",
    ")\n",
    "\n",
    "# ---- Trainer ----\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset, \n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Trainer ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec6e6c",
   "metadata": {},
   "source": [
    "### Ablation 2: reconfigured the classification head for the new 3-class task. \n",
    "- The original HEARTS/EMGSD model was designed for multi-class stereotype categories, which do not align with the Davidson labels. To adapt ALBERT to the new context, I replaced the classification layer so the model outputs three logits for the new classes: Hate Speech (0), Offensive (1), Neither (2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ddc7a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping training ‚Äî already trained.\n"
     ]
    }
   ],
   "source": [
    "if not MODEL_ALREADY_TRAINED:\n",
    "    trainer.train()\n",
    "    trainer.save_model(\"./albert_hatespeech/best_model\")\n",
    "    trainer.save_state()\n",
    "    MODEL_ALREADY_TRAINED = True\n",
    "    print(\"Training complete and model saved.\")\n",
    "else:\n",
    "    print(\"Skipping training ‚Äî already trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "731bed27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='155' max='155' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [155/155 00:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2523157596588135, 'eval_accuracy': 0.9201129715553762, 'eval_f1_macro': 0.745676200079815, 'eval_f1_weighted': 0.9120948251056666, 'eval_runtime': 38.4647, 'eval_samples_per_second': 128.871, 'eval_steps_per_second': 4.03}\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "\n",
    "import json\n",
    "with open(\"eval_results_hatespeech.json\", \"w\") as f:\n",
    "    json.dump(eval_results, f, indent=4)\n",
    "\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b28dcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2523157298564911, 'eval_accuracy': 0.9201129715553762, 'eval_f1_macro': 0.745676200079815, 'eval_f1_weighted': 0.9120948251056666, 'eval_runtime': 33.7242, 'eval_samples_per_second': 146.986, 'eval_steps_per_second': 4.596, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "#SAVED METRICS\n",
    "with open(\"eval_results_hatespeech.json\") as f:\n",
    "    eval_results = json.load(f)\n",
    "\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f7e81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapted_results = {\n",
    "    \"eval_loss\": 0.2523157298564911,\n",
    "    \"eval_accuracy\": 0.9201129715553762,\n",
    "    \"eval_f1_macro\": 0.745676200079815,\n",
    "    \"eval_f1_weighted\": 0.9120948251056666,\n",
    "    \"eval_runtime\": 33.7242,\n",
    "    \"eval_samples_per_second\": 146.986,\n",
    "    \"eval_steps_per_second\": 4.596,\n",
    "    \"epoch\": 3.0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a976cb81",
   "metadata": {},
   "source": [
    "### Evaluation of baseline ALBERT V2 and Davidson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0e943b1-8b7d-437f-a00e-33fc1c605d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Baseline (MGSD ALBERT)</th>\n",
       "      <th>HateSpeech Model</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.833044</td>\n",
       "      <td>0.920113</td>\n",
       "      <td>0.087069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F1 Macro</td>\n",
       "      <td>0.812147</td>\n",
       "      <td>0.745676</td>\n",
       "      <td>-0.066471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1 Weighted</td>\n",
       "      <td>0.831981</td>\n",
       "      <td>0.912095</td>\n",
       "      <td>0.080114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Metric  Baseline (MGSD ALBERT)  HateSpeech Model  Difference\n",
       "0     Accuracy                0.833044          0.920113    0.087069\n",
       "1     F1 Macro                0.812147          0.745676   -0.066471\n",
       "2  F1 Weighted                0.831981          0.912095    0.080114"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# ---- Load ORIGINAL MGSD baseline from ALBERT CSV ----\n",
    "baseline_df = pd.read_csv(\n",
    "    \"HEARTS-Text-Stereotype-Detection/Model Training and Evaluation/\"\n",
    "    \"result_output_albertv2/mgsd_trained/mgsd/classification_report.csv\"\n",
    ")\n",
    "\n",
    "# Extract overall metrics\n",
    "baseline_accuracy = baseline_df.loc[baseline_df[\"Unnamed: 0\"] == \"accuracy\", \"precision\"].values[0]\n",
    "baseline_f1_macro = baseline_df.loc[baseline_df[\"Unnamed: 0\"] == \"macro avg\", \"f1-score\"].values[0]\n",
    "baseline_f1_weighted = baseline_df.loc[baseline_df[\"Unnamed: 0\"] == \"weighted avg\", \"f1-score\"].values[0]\n",
    "\n",
    "baseline_metrics = {\n",
    "    \"eval_accuracy\": baseline_accuracy,\n",
    "    \"eval_f1_macro\": baseline_f1_macro,\n",
    "    \"eval_f1_weighted\": baseline_f1_weighted,\n",
    "}\n",
    "\n",
    "# ---- Load hate-speech adapted model metrics (JSON) ----\n",
    "with open(\"eval_results_hatespeech.json\", \"r\") as f:\n",
    "    adapted_results = json.load(f)\n",
    "\n",
    "# ---- Build comparison table ----\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"F1 Macro\", \"F1 Weighted\"],\n",
    "    \"Baseline (MGSD ALBERT)\": [\n",
    "        baseline_metrics[\"eval_accuracy\"],\n",
    "        baseline_metrics[\"eval_f1_macro\"],\n",
    "        baseline_metrics[\"eval_f1_weighted\"],\n",
    "    ],\n",
    "    \"HateSpeech Model\": [\n",
    "        adapted_results[\"eval_accuracy\"],\n",
    "        adapted_results[\"eval_f1_macro\"],\n",
    "        adapted_results[\"eval_f1_weighted\"],\n",
    "    ],\n",
    "    \"Difference\": [\n",
    "        adapted_results[\"eval_accuracy\"] - baseline_metrics[\"eval_accuracy\"],\n",
    "        adapted_results[\"eval_f1_macro\"] - baseline_metrics[\"eval_f1_macro\"],\n",
    "        adapted_results[\"eval_f1_weighted\"] - baseline_metrics[\"eval_f1_weighted\"],\n",
    "    ],\n",
    "})\n",
    "\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b68d8e49-fdfa-47b0-9912-b3e4515abdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.6147632598876953,\n",
       " 'eval_model_preparation_time': 0.0009,\n",
       " 'eval_accuracy': 0.017693860586628668,\n",
       " 'eval_f1_macro': 0.005987589095235479,\n",
       " 'eval_runtime': 361.4645,\n",
       " 'eval_samples_per_second': 69.891,\n",
       " 'eval_steps_per_second': 4.368}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " with open(\"govuk_eval_results.json\") as f:\n",
    "    results = json.load(f)\n",
    "results\n",
    "# government dataset results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8077cdf-392e-47a3-ae5f-adda2cf77608",
   "metadata": {},
   "source": [
    "### Comparison of Baseline (MGSD ALBERT), Reproduced Baseline, and Hate-Speech Model\n",
    "\n",
    "- I utilised the ALBERT-v2 as the primary baseline as it is the strongest performing model implemented in the official HEARTS codebase, with good macro-F1 performance across the MGSD test set. \n",
    "\n",
    "#### Results: \n",
    "- Accuracy: The MGSD baseline achieves 0.833, while the adapted model reaches 0.920, representing an absolute gain of +0.087. This indicates that the adapted classifier is substantially more effective at distinguishing between hate, offensive, and neutral content than the MGSD model was at stereotype detection.\n",
    "\n",
    "- Macro-F1: The baseline macro-F1 is 0.812, compared to 0.746 for the hate-speech model (a decrease of ‚Äì0.066). This drop is expected because macro-F1 penalises class imbalance, and the Davidson dataset has highly uneven class distributions (majority ‚Äúoffensive‚Äù, minority ‚Äúhate‚Äù). Despite this, the adapted classifier still performs competitively, indicating strong generalisation to minority classes relative to domain difficulty.\n",
    "\n",
    "- Weighted F1:\n",
    "This improves from 0.832 (baseline) to 0.912 (adapted), an increase of +0.080. Indicating that the adapted model performs particularly well on high-frequency classes while still maintaining reasonable generalisation.\n",
    "\n",
    "#### Justification of Metrics:\n",
    "\n",
    "- The original MGSD work uses macro-F1 as its primary model selection metric, with accuracy as a secondary indicator.\n",
    "- Thus, I evaluated the adapted model using the same two metrics to ensure fair, interpretable cross-task comparison. \n",
    "\n",
    "#### Interpretation and Implications\n",
    "\n",
    "- These results indicate a strong performance and show that ALBERT transfers effectively to a domain where the label structure and linguistic phenomena better match the intended application. Accuracy and weighted-F1 support the conclusion that the adapted classifier is significantly stronger for this application than the original MGSD model, which was designed for a different linguistic phenomenon (stereotype detection).\n",
    "\n",
    "- Moreover, the MGSD baseline serves as a benchmark for stereotype-detection quality, whereas the Davidson-trained model represents a re-purposed classifier optimised for online hate-speech detection.\n",
    "\n",
    "- The macro-F1 decrease reflects the increased difficulty of minority-class discrimination in the Davidson dataset, rather than a failure of the model adaptation.\n",
    "\n",
    "\n",
    "#### Conclusion:\n",
    "- Overall, the adapted ALBERT model demonstrates strong and meaningful improvements over the MGSD baseline on task-appropriate metrics, validating the model adaptation pipeline and confirming that ALBERT transfers effectively to hate-speech detection. \n",
    "\n",
    "- The original dataset I tested earlier, GOV.UK job-ad descriptions, did not train well on the HEARTS pipeline due to fundamental mismatches in domain, linguistic style, and label structure. GOV.UK contains long, formal, occupational descriptions with mild or no stereotyping, whereas HEARTS and Davidson‚Äôs hate-speech dataset both contain short, informal, and sentiment-rich social-media text. As a result, the GOV.UK model produced extremely low accuracy and macro-F1 on HEARTS (e.g., accuracy ‚âà 0.017), indicating that it is not an appropriate baseline for evaluating a hate-speech or stereotype-sensitive classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8855e8d3",
   "metadata": {},
   "source": [
    "### Reload Fine-Tuned Model (Reproducibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e80fe14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model + tokenizer reloaded.\n"
     ]
    }
   ],
   "source": [
    "#Davidson dataset\n",
    "\n",
    "from transformers import AlbertForSequenceClassification, AlbertTokenizerFast, Trainer\n",
    "import torch\n",
    "\n",
    "MODEL_PATH = \"./albert_hatespeech/best_model\"   # your saved model folder\n",
    "TOKENIZER_NAME = \"albert-base-v2\"\n",
    "\n",
    "# Load tokenizer + model\n",
    "tokenizer = AlbertTokenizerFast.from_pretrained(TOKENIZER_NAME)\n",
    "model = AlbertForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "\n",
    "print(\"Model + tokenizer reloaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3872e7",
   "metadata": {},
   "source": [
    "### Inference: Generate Predictions on Validation Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7218c4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer ready for prediction (no training).\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "inference_args = TrainingArguments(\n",
    "    output_dir=\"./tmp_inference\",\n",
    "    per_device_eval_batch_size=32,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=inference_args,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "print(\"Trainer ready for prediction (no training).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba07f107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions ready: 4957\n"
     ]
    }
   ],
   "source": [
    "pred_output = trainer.predict(val_dataset)\n",
    "logits = pred_output.predictions\n",
    "y_true = pred_output.label_ids\n",
    "y_pred = logits.argmax(axis=-1)\n",
    "\n",
    "print(\"Predictions ready:\", len(y_true))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec17f87a",
   "metadata": {},
   "source": [
    "### Bootstrap significance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0abc742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.920 (95% CI: 0.913 ‚Äì 0.928)\n",
      "Macro-F1: 0.746 (95% CI: 0.724 ‚Äì 0.767)\n"
     ]
    }
   ],
   "source": [
    "# Bootstrap Significance Test + Visual \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def bootstrap_scores(y_true, y_pred, metric_fn, n_boot=1000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(y_true)\n",
    "    scores = []\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "        scores.append(metric_fn(y_true[idx], y_pred[idx]))\n",
    "    return np.array(scores)\n",
    "\n",
    "# Accuracy \n",
    "\n",
    "acc_scores = bootstrap_scores(y_true, y_pred, accuracy_score)\n",
    "acc_mean = acc_scores.mean()\n",
    "acc_ci = np.percentile(acc_scores, [2.5, 97.5])\n",
    "\n",
    "# Macro F1\n",
    "\n",
    "f1_scores = bootstrap_scores(\n",
    "    y_true, \n",
    "    y_pred, \n",
    "    lambda yt, yp: f1_score(yt, yp, average=\"macro\")\n",
    ")\n",
    "f1_mean = f1_scores.mean()\n",
    "f1_ci = np.percentile(f1_scores, [2.5, 97.5])\n",
    "\n",
    "print(f\"Accuracy: {acc_mean:.3f} (95% CI: {acc_ci[0]:.3f} ‚Äì {acc_ci[1]:.3f})\")\n",
    "print(f\"Macro-F1: {f1_mean:.3f} (95% CI: {f1_ci[0]:.3f} ‚Äì {f1_ci[1]:.3f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ab3383e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram Visualisation\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(acc_scores, bins=30)\n",
    "plt.axvline(acc_mean, linestyle=\"--\", label=\"Mean\")\n",
    "plt.axvline(acc_ci[0], linestyle=\":\", label=\"95% CI Low\")\n",
    "plt.axvline(acc_ci[1], linestyle=\":\", label=\"95% CI High\")\n",
    "\n",
    "plt.title(\"Bootstrap Accuracy Distribution (1000 samples)\")\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81c6f99-726a-4cb7-bd72-143df5587b12",
   "metadata": {},
   "source": [
    "Bootstrap resampling (1,000 iterations) shows that the adapted hate-speech model achieves highly stable performance, with accuracy = 0.920 (95% CI: 0.913‚Äì0.928) and macro-F1 = 0.746 (95% CI: 0.724‚Äì0.767), indicating statistically robust estimates with low variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc31505",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9ede3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_hate_speech</th>\n",
       "      <th>pred_offensive</th>\n",
       "      <th>pred_neither</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_hate_speech</th>\n",
       "      <td>81</td>\n",
       "      <td>185</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_offensive</th>\n",
       "      <td>57</td>\n",
       "      <td>3708</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_neither</th>\n",
       "      <td>8</td>\n",
       "      <td>53</td>\n",
       "      <td>772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pred_hate_speech  pred_offensive  pred_neither\n",
       "true_hate_speech                81             185            20\n",
       "true_offensive                  57            3708            73\n",
       "true_neither                     8              53           772"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "labels = {0: \"hate_speech\", 1: \"offensive\", 2: \"neither\"}  \n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_df = pd.DataFrame(cm,\n",
    "                     index=[f\"true_{labels[i]}\" for i in range(3)],\n",
    "                     columns=[f\"pred_{labels[i]}\" for i in range(3)])\n",
    "cm_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cc649bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f2ebc4df730>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_true = val_df[\"class\"].tolist()\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6537d0b8",
   "metadata": {},
   "source": [
    "**Class Labels:**  \n",
    "0 ‚Üí Hate Speech  \n",
    "1 ‚Üí Offensive Language  \n",
    "2 ‚Üí Neither "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a1204e",
   "metadata": {},
   "source": [
    "### Confusion Matrix - Interpretation:\n",
    "\n",
    "The confusion matrix indicates that the adapted ALBERT model performs strongly overall, with most samples in the 'Offensive' and 'Neither' classes correctly classified. The largest number of correct predictions lies on the diagonal for these categories, supporting the high overall accuracy and weighted F1 score.\n",
    "\n",
    "The main limitation appears in the 'Hate Speech' class, where many instances are misclassified as 'Offensive'. \n",
    "Overall, the model is reliable at distinguishing neutral versus harmful content, but shows reduced sensitivity for the minority hate-speech class, indicating a potential area for future improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadab756",
   "metadata": {},
   "source": [
    "### Failure Case Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50e3f41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 4957, misclassified: 396\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>true_id</th>\n",
       "      <th>pred_id</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>is_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>@goodgraces_ ok faggot http://t.co/zdGtE9GvzX</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>offensive</td>\n",
       "      <td>hate_speech</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Noap. Not taking them. RT @TiffNCompany: Maca ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>neither</td>\n",
       "      <td>offensive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>@RniSwirvinn @LilKev_J no ur wrong stupid nigger</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>People who never use any hair product are unke...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>offensive</td>\n",
       "      <td>hate_speech</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>@LaBugg09 &amp;#128514;&amp;#128514; my fault it sound...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>neither</td>\n",
       "      <td>offensive</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  true_id  pred_id  \\\n",
       "23      @goodgraces_ ok faggot http://t.co/zdGtE9GvzX        1        0   \n",
       "44  Noap. Not taking them. RT @TiffNCompany: Maca ...        2        1   \n",
       "56   @RniSwirvinn @LilKev_J no ur wrong stupid nigger        0        1   \n",
       "68  People who never use any hair product are unke...        1        0   \n",
       "83  @LaBugg09 &#128514;&#128514; my fault it sound...        2        1   \n",
       "\n",
       "     true_label   pred_label  is_correct  \n",
       "23    offensive  hate_speech       False  \n",
       "44      neither    offensive       False  \n",
       "56  hate_speech    offensive       False  \n",
       "68    offensive  hate_speech       False  \n",
       "83      neither    offensive       False  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "label_map = {0: \"hate_speech\", 1: \"offensive\", 2: \"neither\"}\n",
    "\n",
    "y_true_arr = np.array(y_true)\n",
    "y_pred_arr = np.array(y_pred)\n",
    "\n",
    "# Build dataframe with predictions + labels\n",
    "failure_df = pd.DataFrame({\n",
    "    \"text\": val_df[\"tweet\"].values,        \n",
    "    \"true_id\": y_true_arr,\n",
    "    \"pred_id\": y_pred_arr,\n",
    "})\n",
    "\n",
    "failure_df[\"true_label\"] = failure_df[\"true_id\"].map(label_map)\n",
    "failure_df[\"pred_label\"] = failure_df[\"pred_id\"].map(label_map)\n",
    "failure_df[\"is_correct\"] = failure_df[\"true_id\"] == failure_df[\"pred_id\"]\n",
    "\n",
    "# All misclassified examples\n",
    "errors_df = failure_df[~failure_df[\"is_correct\"]].copy()\n",
    "print(f\"Total examples: {len(failure_df)}, misclassified: {len(errors_df)}\")\n",
    "errors_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "837aed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "def show_errors(true_label=None, pred_label=None, n=10):\n",
    "    \"\"\"\n",
    "    Inspect failure cases.\n",
    "    - true_label / pred_label: use string labels, e.g. \"hate_speech\", \"offensive\", \"neither\"\n",
    "    - n: number of rows to show\n",
    "    \"\"\"\n",
    "    df = errors_df.copy()\n",
    "    if true_label is not None:\n",
    "        df = df[df[\"true_label\"] == true_label]\n",
    "    if pred_label is not None:\n",
    "        df = df[df[\"pred_label\"] == pred_label]\n",
    "        \n",
    "    cols = [\"true_label\", \"pred_label\", \"text\"]\n",
    "    display(df[cols].head(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a057ba",
   "metadata": {},
   "source": [
    "### 1. False Negatives ‚Äì Hate Speech instances incorrectly classified as non-hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f94f9d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>@RniSwirvinn @LilKev_J no ur wrong stupid nigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @lildurk_: I don't fuck with bitch niggas I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>neither</td>\n",
       "      <td>Stupid teabagger restaurant making customers p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>@_SoulSurvivor_ @zakbauer I dont have any prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Lmao let these hoes be hoes ain't no Savin nem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @imDOPE_GetHigh: @Whackko man some lame nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>harm this pussy instead RT @ABC7: missing 26-y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>RT \"@_ThatGAPeach: &amp;amp; alla my niggas hot bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>niggas ain't playin a gram of defense man Geor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>neither</td>\n",
       "      <td>\"Let's kill cracker babies!\". WTF did I just h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      true_label pred_label                                               text\n",
       "56   hate_speech  offensive   @RniSwirvinn @LilKev_J no ur wrong stupid nigger\n",
       "128  hate_speech  offensive  RT @lildurk_: I don't fuck with bitch niggas I...\n",
       "143  hate_speech    neither  Stupid teabagger restaurant making customers p...\n",
       "158  hate_speech  offensive  @_SoulSurvivor_ @zakbauer I dont have any prob...\n",
       "189  hate_speech  offensive     Lmao let these hoes be hoes ain't no Savin nem\n",
       "216  hate_speech  offensive  RT @imDOPE_GetHigh: @Whackko man some lame nig...\n",
       "255  hate_speech  offensive  harm this pussy instead RT @ABC7: missing 26-y...\n",
       "327  hate_speech  offensive  RT \"@_ThatGAPeach: &amp; alla my niggas hot bo...\n",
       "344  hate_speech  offensive  niggas ain't playin a gram of defense man Geor...\n",
       "348  hate_speech    neither  \"Let's kill cracker babies!\". WTF did I just h..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. False Negatives ‚Äì Hate Speech instances incorrectly classified as non-hate\n",
    "show_errors(true_label=\"hate_speech\", n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eacb563",
   "metadata": {},
   "source": [
    "### 2. Hate Speech ‚Üí Offensive Language Misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c895853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>@RniSwirvinn @LilKev_J no ur wrong stupid nigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @lildurk_: I don't fuck with bitch niggas I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>@_SoulSurvivor_ @zakbauer I dont have any prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Lmao let these hoes be hoes ain't no Savin nem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @imDOPE_GetHigh: @Whackko man some lame nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>harm this pussy instead RT @ABC7: missing 26-y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>RT \"@_ThatGAPeach: &amp;amp; alla my niggas hot bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>niggas ain't playin a gram of defense man Geor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>@FreddyAmazin ratchet looking nigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @GottaLuvLexci_: &amp;#128557;&amp;#128557;&amp;#128557...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      true_label pred_label                                               text\n",
       "56   hate_speech  offensive   @RniSwirvinn @LilKev_J no ur wrong stupid nigger\n",
       "128  hate_speech  offensive  RT @lildurk_: I don't fuck with bitch niggas I...\n",
       "158  hate_speech  offensive  @_SoulSurvivor_ @zakbauer I dont have any prob...\n",
       "189  hate_speech  offensive     Lmao let these hoes be hoes ain't no Savin nem\n",
       "216  hate_speech  offensive  RT @imDOPE_GetHigh: @Whackko man some lame nig...\n",
       "255  hate_speech  offensive  harm this pussy instead RT @ABC7: missing 26-y...\n",
       "327  hate_speech  offensive  RT \"@_ThatGAPeach: &amp; alla my niggas hot bo...\n",
       "344  hate_speech  offensive  niggas ain't playin a gram of defense man Geor...\n",
       "375  hate_speech  offensive               @FreddyAmazin ratchet looking nigger\n",
       "383  hate_speech  offensive  RT @GottaLuvLexci_: &#128557;&#128557;&#128557..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Hate Speech ‚Üí Offensive Language Misclassification\n",
    "show_errors(true_label=\"hate_speech\", pred_label=\"offensive\", n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e515d6c2",
   "metadata": {},
   "source": [
    "### 3. False Positives ‚Äì Neutral/Non-Toxic Content incorrectly flagged as Offensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6dcb0997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>neither</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Noap. Not taking them. RT @TiffNCompany: Maca ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>neither</td>\n",
       "      <td>offensive</td>\n",
       "      <td>@LaBugg09 &amp;#128514;&amp;#128514; my fault it sound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>neither</td>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @StonerBoii2cold: &amp;#8220;@TreVaughnLG: Moma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>neither</td>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @Alleycelestine: &amp;#8220;@ViriDoesItt: Kissi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>neither</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Where's the part where Fat Amy goes err wop wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>neither</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Nah. ITS OVER&amp;gt; People don't tell #artists w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>neither</td>\n",
       "      <td>offensive</td>\n",
       "      <td>@patrickkimmis @White1979 Remember Dad running...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>neither</td>\n",
       "      <td>offensive</td>\n",
       "      <td>I mean most ppl confuse when to use \"to\" and \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>neither</td>\n",
       "      <td>offensive</td>\n",
       "      <td>McDonald's is hella trash to me now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>neither</td>\n",
       "      <td>offensive</td>\n",
       "      <td>@JustDoItSlow &amp;#128530;FOREVER 21 hoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     true_label pred_label                                               text\n",
       "44      neither  offensive  Noap. Not taking them. RT @TiffNCompany: Maca ...\n",
       "83      neither  offensive  @LaBugg09 &#128514;&#128514; my fault it sound...\n",
       "284     neither  offensive  RT @StonerBoii2cold: &#8220;@TreVaughnLG: Moma...\n",
       "299     neither  offensive  RT @Alleycelestine: &#8220;@ViriDoesItt: Kissi...\n",
       "543     neither  offensive  Where's the part where Fat Amy goes err wop wo...\n",
       "598     neither  offensive  Nah. ITS OVER&gt; People don't tell #artists w...\n",
       "606     neither  offensive  @patrickkimmis @White1979 Remember Dad running...\n",
       "755     neither  offensive  I mean most ppl confuse when to use \"to\" and \"...\n",
       "1021    neither  offensive                McDonald's is hella trash to me now\n",
       "1088    neither  offensive             @JustDoItSlow &#128530;FOREVER 21 hoes"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. False Positives ‚Äì Neutral/Non-Toxic Content incorrectly flagged as Offensive\n",
    "show_errors(true_label=\"neither\", pred_label=\"offensive\", n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9738d8",
   "metadata": {},
   "source": [
    "### 4. Top-10 high-confidence wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68790451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "probs = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "max_conf = probs.max(axis=1)\n",
    "\n",
    "failure_df[\"confidence\"] = max_conf\n",
    "errors_df = failure_df[~failure_df[\"is_correct\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8d1c74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>0.997011</td>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>You&amp;#8217;re a little bitch RT @FuckingCashBro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0.996329</td>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @Juicy_Squeaky: Any bitch who need a crowd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4873</th>\n",
       "      <td>0.996188</td>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @jasminee_gamboa: hoes will be hoes .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>0.996002</td>\n",
       "      <td>neither</td>\n",
       "      <td>offensive</td>\n",
       "      <td>@JustDoItSlow &amp;#128530;FOREVER 21 hoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.995673</td>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>harm this pussy instead RT @ABC7: missing 26-y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4003</th>\n",
       "      <td>0.995558</td>\n",
       "      <td>neither</td>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @I_Be_kOoLz Food be good...except that rice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.995549</td>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>Lmao let these hoes be hoes ain't no Savin nem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>0.995259</td>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>I hate dumb bitches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2509</th>\n",
       "      <td>0.995184</td>\n",
       "      <td>neither</td>\n",
       "      <td>offensive</td>\n",
       "      <td>and another one &amp;#8220;@07Cannon: Two hoes? RT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>0.995044</td>\n",
       "      <td>hate_speech</td>\n",
       "      <td>offensive</td>\n",
       "      <td>RT @Tyler_Weddle_23: &amp;#8220;@Sexualgif: \"I hat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      confidence   true_label pred_label  \\\n",
       "2994    0.997011  hate_speech  offensive   \n",
       "635     0.996329  hate_speech  offensive   \n",
       "4873    0.996188  hate_speech  offensive   \n",
       "1088    0.996002      neither  offensive   \n",
       "255     0.995673  hate_speech  offensive   \n",
       "4003    0.995558      neither  offensive   \n",
       "189     0.995549  hate_speech  offensive   \n",
       "1241    0.995259  hate_speech  offensive   \n",
       "2509    0.995184      neither  offensive   \n",
       "1610    0.995044  hate_speech  offensive   \n",
       "\n",
       "                                                   text  \n",
       "2994  You&#8217;re a little bitch RT @FuckingCashBro...  \n",
       "635   RT @Juicy_Squeaky: Any bitch who need a crowd ...  \n",
       "4873           RT @jasminee_gamboa: hoes will be hoes .  \n",
       "1088             @JustDoItSlow &#128530;FOREVER 21 hoes  \n",
       "255   harm this pussy instead RT @ABC7: missing 26-y...  \n",
       "4003  RT @I_Be_kOoLz Food be good...except that rice...  \n",
       "189      Lmao let these hoes be hoes ain't no Savin nem  \n",
       "1241                                I hate dumb bitches  \n",
       "2509  and another one &#8220;@07Cannon: Two hoes? RT...  \n",
       "1610  RT @Tyler_Weddle_23: &#8220;@Sexualgif: \"I hat...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top-10 highest-confidence wrong predictions\n",
    "high_conf_errors = errors_df.sort_values(\"confidence\", ascending=False)[\n",
    "    [\"confidence\", \"true_label\", \"pred_label\", \"text\"]\n",
    "].head(10)\n",
    "\n",
    "high_conf_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968a934",
   "metadata": {},
   "source": [
    "### Failure Case Analysis \n",
    "\n",
    "To systematically assess the remaining limitations of the adapted model, 396 misclassified instances were examined, representing 8% of the validation set. Error distribution analysis indicates that the majority of misclassifications occur between the hate_speech and offensive classes, as reflected by the largest off-diagonal values in the confusion matrix.\n",
    "\n",
    "A recurrent pattern is the prediction of offensive when the ground truth label is hate_speech, suggesting reduced recall for the minority hate-speech category. High-confidence error inspection further reveals multiple instances where the model assigns >99% probability to incorrect labels, indicating systematic boundary or calibration issues rather than random noise.\n",
    "\n",
    "Qualitative inspection of these high-confidence errors shows that many examples contain lexical profanity, reclaimed slurs, or informal dialectal language (e.g., AAVE). This suggests that the classifier disproportionately relies on surface lexical cues instead of contextual or target-specific semantic signals. Conversely, several non-toxic (‚Äúneither‚Äù) tweets are misclassified as offensive, implying an over-sensitivity to swear words in the absence of harmful intent.\n",
    "\n",
    "Collectively, these findings indicate that although the adapted model demonstrates a substantial macro-F1 improvement, residual weaknesses persist in distinguishing abusive language subtypes that differ primarily in intent, target specificity, and pragmatic context, rather than explicit lexical content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6225651a-166b-4ef7-9dfd-d2a50cfccdc3",
   "metadata": {},
   "source": [
    "\n",
    "### 4 Main Failure Cases & Possible future improvements: \n",
    "\n",
    "1. **Hate Speech Misclassified as Offensive:**\n",
    "The model frequently under-detects hate speech when profanity or slurs resemble general offensive language (Figure 1). This pattern is likely influenced by class imbalance, where the offensive category constitutes approximately 77% of the dataset, biasing the classifier toward the majority class.\n",
    "\n",
    "**Possible Improvements:** \n",
    "- Introduce target-aware modelling (who is being targeted, not just what words are used).\n",
    "- Apply class-weighted loss or focal loss to counter class imbalance.\n",
    "- Expand training data with minority hate-speech examples and ethically sourced targeted-hate datasets.\n",
    "\n",
    "2. **High-Confidence Incorrect Predictions:**\n",
    "Several misclassifications occur with >99% predicted probability (Figure 2), indicating systematic decision-boundary or calibration issues rather than random noise. These errors suggest the model is confidently relying on misleading lexical cues.\n",
    "\n",
    "**Possible Improvements:** \n",
    "- Use probability calibration methods (e.g., temperature scaling, Platt scaling).\n",
    "- Implement hard-negative mining to retrain on confidently misclassified samples.\n",
    "- Add uncertainty estimation or confidence thresholds before final classification.\n",
    "\n",
    "3. **Quoted or Indirect Speech Failures:**\n",
    "The model struggles to distinguish between the author‚Äôs voice and quoted or reported speech, often interpreting quoted content as the speaker‚Äôs own stance. This reflects a limitation in discourse-level and speaker-attribution understanding.\n",
    "\n",
    "**Possible Improvements:** \n",
    "- Incorporate context-window or conversation-history models instead of single-tweet inputs.\n",
    "- Add discourse-aware or sarcasm/pragmatics modules.\n",
    "- Train with annotated quote / reply / retweet metadata to model speaker attribution.\n",
    "\n",
    "4. **Implicit or Coded Hate Speech:**\n",
    "Slur-free but semantically harmful statements are frequently misclassified, demonstrating difficulty with pragmatic inference and contextual nuance. These cases lack explicit lexical markers yet convey discriminatory intent (e.g., indirect exclusionary phrases), revealing limitations in intent and target recognition.\n",
    "\n",
    "**Possible Improvements:** \n",
    "\n",
    "- Use continual learning or dynamic lexicon updates to adapt to evolving coded language.\n",
    "- Integrate semantic or knowledge-graph features to capture indirect hostility.\n",
    "- Explore multi-task learning with intent and target detection rather than surface toxicity alone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8792bc",
   "metadata": {},
   "source": [
    "## Discussion & Critical Reflections on SDGs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621d5a6d",
   "metadata": {},
   "source": [
    "### Critical Reflections on SDGs:\n",
    "\n",
    "- Across SDGs 5, 10, and 16, the model‚Äôs contributions are meaningful but conditional on governed implementation and adaptation of the model according to the failure cases. \n",
    "- The confusion matrix and failure-case analysis show that the model struggles with pragmatic inference, context tracking, quoted content, sarcasm, and implicit or coded hate. \n",
    "- These weaknesses create potential blind spots that could undermine progress toward reducing inequality and protecting marginalised groups. \n",
    "- Ethically, automated moderation systems risk reinforcing biases if not carefully audited. \n",
    "- False negatives may allow harmful content to persist, while false positives may disproportionately silence certain communities, especially those using reclaimed language or non-standard dialects.\n",
    "\n",
    "### Ethical Implications:\n",
    "- The over-reliance on lexical cues which can cause marginalised communities to become undermined, if reclaiming terms.\n",
    "- Failure cases need to be fixed before scaling, as they can enable harmful messages to persist conflicting with SDGs 5 & 10.\n",
    "- Bias Propagation: The dataset is imbalanced and relies heavily on surface level toxic keywords and lacks identity labels.\n",
    "\n",
    "### Actionable Policy & Recommendations:\n",
    "- Regular bias auditing & monitoring ‚Äì supporting sdg 16\n",
    "- Guardrails Against Over-Reliance on Lexical Cues ‚Äì supports sdg 10, mitigating discriminatory behaviour\n",
    "- For scalability - training data diversification across dialects and global regions and possibly expanded to detection against certain groups."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
