[
    {
        "loss": 2.6208,
        "grad_norm": 41.82966995239258,
        "learning_rate": 1.9860671310956303e-05,
        "epoch": 0.021110407430863416,
        "step": 100
    },
    {
        "loss": 2.061,
        "grad_norm": 21.27790641784668,
        "learning_rate": 1.9719935261417213e-05,
        "epoch": 0.04222081486172683,
        "step": 200
    },
    {
        "loss": 1.7166,
        "grad_norm": 32.993568420410156,
        "learning_rate": 1.9579199211878124e-05,
        "epoch": 0.06333122229259025,
        "step": 300
    },
    {
        "loss": 1.665,
        "grad_norm": 31.47670555114746,
        "learning_rate": 1.9438463162339034e-05,
        "epoch": 0.08444162972345366,
        "step": 400
    },
    {
        "loss": 1.4771,
        "grad_norm": 32.252017974853516,
        "learning_rate": 1.9297727112799944e-05,
        "epoch": 0.10555203715431707,
        "step": 500
    },
    {
        "loss": 1.3466,
        "grad_norm": 26.368806838989258,
        "learning_rate": 1.9156991063260857e-05,
        "epoch": 0.1266624445851805,
        "step": 600
    },
    {
        "loss": 1.171,
        "grad_norm": 31.040725708007812,
        "learning_rate": 1.9016255013721767e-05,
        "epoch": 0.1477728520160439,
        "step": 700
    },
    {
        "loss": 1.2269,
        "grad_norm": 20.647611618041992,
        "learning_rate": 1.8875518964182678e-05,
        "epoch": 0.16888325944690732,
        "step": 800
    },
    {
        "loss": 1.2249,
        "grad_norm": 21.92112159729004,
        "learning_rate": 1.8734782914643588e-05,
        "epoch": 0.18999366687777075,
        "step": 900
    },
    {
        "loss": 1.1253,
        "grad_norm": 21.02688980102539,
        "learning_rate": 1.8594046865104498e-05,
        "epoch": 0.21110407430863415,
        "step": 1000
    },
    {
        "loss": 1.1504,
        "grad_norm": 33.300296783447266,
        "learning_rate": 1.8453310815565408e-05,
        "epoch": 0.23221448173949757,
        "step": 1100
    },
    {
        "loss": 1.1085,
        "grad_norm": 25.510425567626953,
        "learning_rate": 1.8312574766026318e-05,
        "epoch": 0.253324889170361,
        "step": 1200
    },
    {
        "loss": 1.0549,
        "grad_norm": 29.08519172668457,
        "learning_rate": 1.8171838716487228e-05,
        "epoch": 0.2744352966012244,
        "step": 1300
    },
    {
        "loss": 1.0545,
        "grad_norm": 30.014867782592773,
        "learning_rate": 1.803110266694814e-05,
        "epoch": 0.2955457040320878,
        "step": 1400
    },
    {
        "loss": 0.9952,
        "grad_norm": 30.071304321289062,
        "learning_rate": 1.7890366617409052e-05,
        "epoch": 0.31665611146295125,
        "step": 1500
    },
    {
        "loss": 1.0676,
        "grad_norm": 21.596210479736328,
        "learning_rate": 1.7749630567869962e-05,
        "epoch": 0.33776651889381465,
        "step": 1600
    },
    {
        "loss": 0.9455,
        "grad_norm": 25.005661010742188,
        "learning_rate": 1.7608894518330872e-05,
        "epoch": 0.35887692632467805,
        "step": 1700
    },
    {
        "loss": 0.967,
        "grad_norm": 16.353870391845703,
        "learning_rate": 1.7468158468791782e-05,
        "epoch": 0.3799873337555415,
        "step": 1800
    },
    {
        "loss": 0.9149,
        "grad_norm": 44.91099166870117,
        "learning_rate": 1.7327422419252692e-05,
        "epoch": 0.4010977411864049,
        "step": 1900
    },
    {
        "loss": 0.941,
        "grad_norm": 29.37477684020996,
        "learning_rate": 1.7186686369713603e-05,
        "epoch": 0.4222081486172683,
        "step": 2000
    },
    {
        "loss": 0.9296,
        "grad_norm": 19.267818450927734,
        "learning_rate": 1.7045950320174513e-05,
        "epoch": 0.44331855604813175,
        "step": 2100
    },
    {
        "loss": 0.9393,
        "grad_norm": 32.55929946899414,
        "learning_rate": 1.6905214270635423e-05,
        "epoch": 0.46442896347899515,
        "step": 2200
    },
    {
        "loss": 0.9056,
        "grad_norm": 26.579544067382812,
        "learning_rate": 1.6764478221096333e-05,
        "epoch": 0.48553937090985855,
        "step": 2300
    },
    {
        "loss": 0.9138,
        "grad_norm": 29.293909072875977,
        "learning_rate": 1.6623742171557246e-05,
        "epoch": 0.506649778340722,
        "step": 2400
    },
    {
        "loss": 0.913,
        "grad_norm": 52.301185607910156,
        "learning_rate": 1.6483006122018157e-05,
        "epoch": 0.5277601857715853,
        "step": 2500
    },
    {
        "loss": 0.8628,
        "grad_norm": 34.64277648925781,
        "learning_rate": 1.6342270072479067e-05,
        "epoch": 0.5488705932024488,
        "step": 2600
    },
    {
        "loss": 0.8902,
        "grad_norm": 33.2155647277832,
        "learning_rate": 1.6201534022939977e-05,
        "epoch": 0.5699810006333123,
        "step": 2700
    },
    {
        "loss": 0.8102,
        "grad_norm": 43.525753021240234,
        "learning_rate": 1.6060797973400887e-05,
        "epoch": 0.5910914080641756,
        "step": 2800
    },
    {
        "loss": 0.7943,
        "grad_norm": 14.308030128479004,
        "learning_rate": 1.5920061923861797e-05,
        "epoch": 0.612201815495039,
        "step": 2900
    },
    {
        "loss": 0.8344,
        "grad_norm": 19.08730125427246,
        "learning_rate": 1.5779325874322707e-05,
        "epoch": 0.6333122229259025,
        "step": 3000
    },
    {
        "loss": 0.7838,
        "grad_norm": 28.293468475341797,
        "learning_rate": 1.5638589824783617e-05,
        "epoch": 0.6544226303567658,
        "step": 3100
    },
    {
        "loss": 0.8145,
        "grad_norm": 21.274198532104492,
        "learning_rate": 1.5497853775244527e-05,
        "epoch": 0.6755330377876293,
        "step": 3200
    },
    {
        "loss": 0.8006,
        "grad_norm": 40.05744171142578,
        "learning_rate": 1.535711772570544e-05,
        "epoch": 0.6966434452184928,
        "step": 3300
    },
    {
        "loss": 0.8388,
        "grad_norm": 24.310182571411133,
        "learning_rate": 1.5216381676166351e-05,
        "epoch": 0.7177538526493561,
        "step": 3400
    },
    {
        "loss": 0.824,
        "grad_norm": 19.9592342376709,
        "learning_rate": 1.5075645626627263e-05,
        "epoch": 0.7388642600802195,
        "step": 3500
    },
    {
        "loss": 0.8792,
        "grad_norm": 52.153446197509766,
        "learning_rate": 1.4934909577088173e-05,
        "epoch": 0.759974667511083,
        "step": 3600
    },
    {
        "loss": 0.8052,
        "grad_norm": 19.966201782226562,
        "learning_rate": 1.4794173527549083e-05,
        "epoch": 0.7810850749419463,
        "step": 3700
    },
    {
        "loss": 0.8021,
        "grad_norm": 41.86872482299805,
        "learning_rate": 1.4653437478009993e-05,
        "epoch": 0.8021954823728098,
        "step": 3800
    },
    {
        "loss": 0.73,
        "grad_norm": 30.52226448059082,
        "learning_rate": 1.4512701428470903e-05,
        "epoch": 0.8233058898036733,
        "step": 3900
    },
    {
        "loss": 0.7428,
        "grad_norm": 26.64560317993164,
        "learning_rate": 1.4371965378931814e-05,
        "epoch": 0.8444162972345366,
        "step": 4000
    },
    {
        "loss": 0.7745,
        "grad_norm": 22.474077224731445,
        "learning_rate": 1.4231229329392725e-05,
        "epoch": 0.8655267046654,
        "step": 4100
    },
    {
        "loss": 0.7789,
        "grad_norm": 45.14017105102539,
        "learning_rate": 1.4090493279853637e-05,
        "epoch": 0.8866371120962635,
        "step": 4200
    },
    {
        "loss": 0.8014,
        "grad_norm": 34.53644561767578,
        "learning_rate": 1.3949757230314547e-05,
        "epoch": 0.9077475195271268,
        "step": 4300
    },
    {
        "loss": 0.72,
        "grad_norm": 38.98872375488281,
        "learning_rate": 1.3809021180775457e-05,
        "epoch": 0.9288579269579903,
        "step": 4400
    },
    {
        "loss": 0.7112,
        "grad_norm": 26.834308624267578,
        "learning_rate": 1.3668285131236368e-05,
        "epoch": 0.9499683343888538,
        "step": 4500
    },
    {
        "loss": 0.7451,
        "grad_norm": 47.21794509887695,
        "learning_rate": 1.3527549081697278e-05,
        "epoch": 0.9710787418197171,
        "step": 4600
    },
    {
        "loss": 0.7677,
        "grad_norm": 34.8702507019043,
        "learning_rate": 1.3386813032158188e-05,
        "epoch": 0.9921891492505805,
        "step": 4700
    },
    {
        "loss": 0.6967,
        "grad_norm": 41.54818344116211,
        "learning_rate": 1.3246076982619098e-05,
        "epoch": 1.013299556681444,
        "step": 4800
    },
    {
        "loss": 0.6313,
        "grad_norm": 17.881921768188477,
        "learning_rate": 1.3105340933080008e-05,
        "epoch": 1.0344099641123075,
        "step": 4900
    },
    {
        "loss": 0.6404,
        "grad_norm": 85.5865478515625,
        "learning_rate": 1.2964604883540922e-05,
        "epoch": 1.0555203715431707,
        "step": 5000
    },
    {
        "loss": 0.6411,
        "grad_norm": 15.220657348632812,
        "learning_rate": 1.2823868834001832e-05,
        "epoch": 1.0766307789740341,
        "step": 5100
    },
    {
        "loss": 0.6039,
        "grad_norm": 39.30961990356445,
        "learning_rate": 1.2683132784462742e-05,
        "epoch": 1.0977411864048976,
        "step": 5200
    },
    {
        "loss": 0.6299,
        "grad_norm": 27.550832748413086,
        "learning_rate": 1.2542396734923652e-05,
        "epoch": 1.118851593835761,
        "step": 5300
    },
    {
        "loss": 0.5771,
        "grad_norm": 30.52118492126465,
        "learning_rate": 1.2401660685384562e-05,
        "epoch": 1.1399620012666245,
        "step": 5400
    },
    {
        "loss": 0.6242,
        "grad_norm": 50.91707229614258,
        "learning_rate": 1.2260924635845472e-05,
        "epoch": 1.161072408697488,
        "step": 5500
    },
    {
        "loss": 0.6369,
        "grad_norm": 50.84226608276367,
        "learning_rate": 1.2120188586306382e-05,
        "epoch": 1.1821828161283512,
        "step": 5600
    },
    {
        "loss": 0.637,
        "grad_norm": 49.48912048339844,
        "learning_rate": 1.1979452536767292e-05,
        "epoch": 1.2032932235592146,
        "step": 5700
    },
    {
        "loss": 0.592,
        "grad_norm": 40.07371520996094,
        "learning_rate": 1.1838716487228204e-05,
        "epoch": 1.224403630990078,
        "step": 5800
    },
    {
        "loss": 0.6075,
        "grad_norm": 27.889225006103516,
        "learning_rate": 1.1697980437689116e-05,
        "epoch": 1.2455140384209415,
        "step": 5900
    },
    {
        "loss": 0.613,
        "grad_norm": 40.5655403137207,
        "learning_rate": 1.1557244388150026e-05,
        "epoch": 1.266624445851805,
        "step": 6000
    },
    {
        "loss": 0.6328,
        "grad_norm": 34.47039031982422,
        "learning_rate": 1.1416508338610936e-05,
        "epoch": 1.2877348532826685,
        "step": 6100
    },
    {
        "loss": 0.5703,
        "grad_norm": 34.292232513427734,
        "learning_rate": 1.1275772289071846e-05,
        "epoch": 1.3088452607135317,
        "step": 6200
    },
    {
        "loss": 0.6161,
        "grad_norm": 39.954689025878906,
        "learning_rate": 1.1135036239532757e-05,
        "epoch": 1.3299556681443951,
        "step": 6300
    },
    {
        "loss": 0.6091,
        "grad_norm": 27.270692825317383,
        "learning_rate": 1.0994300189993667e-05,
        "epoch": 1.3510660755752586,
        "step": 6400
    },
    {
        "loss": 0.5435,
        "grad_norm": 18.473173141479492,
        "learning_rate": 1.0853564140454579e-05,
        "epoch": 1.372176483006122,
        "step": 6500
    },
    {
        "loss": 0.5767,
        "grad_norm": 31.755144119262695,
        "learning_rate": 1.0712828090915489e-05,
        "epoch": 1.3932868904369855,
        "step": 6600
    },
    {
        "loss": 0.633,
        "grad_norm": 44.448219299316406,
        "learning_rate": 1.0572092041376399e-05,
        "epoch": 1.4143972978678487,
        "step": 6700
    },
    {
        "loss": 0.6198,
        "grad_norm": 35.166446685791016,
        "learning_rate": 1.043135599183731e-05,
        "epoch": 1.4355077052987122,
        "step": 6800
    },
    {
        "loss": 0.6058,
        "grad_norm": 25.172218322753906,
        "learning_rate": 1.029061994229822e-05,
        "epoch": 1.4566181127295756,
        "step": 6900
    },
    {
        "loss": 0.6119,
        "grad_norm": 27.06463623046875,
        "learning_rate": 1.0149883892759131e-05,
        "epoch": 1.477728520160439,
        "step": 7000
    },
    {
        "loss": 0.6275,
        "grad_norm": 30.893007278442383,
        "learning_rate": 1.0009147843220041e-05,
        "epoch": 1.4988389275913026,
        "step": 7100
    },
    {
        "loss": 0.5767,
        "grad_norm": 27.468387603759766,
        "learning_rate": 9.868411793680953e-06,
        "epoch": 1.519949335022166,
        "step": 7200
    },
    {
        "loss": 0.6559,
        "grad_norm": 32.196983337402344,
        "learning_rate": 9.727675744141863e-06,
        "epoch": 1.5410597424530295,
        "step": 7300
    },
    {
        "loss": 0.5977,
        "grad_norm": 33.884796142578125,
        "learning_rate": 9.586939694602773e-06,
        "epoch": 1.562170149883893,
        "step": 7400
    },
    {
        "loss": 0.574,
        "grad_norm": 42.653663635253906,
        "learning_rate": 9.446203645063685e-06,
        "epoch": 1.5832805573147561,
        "step": 7500
    },
    {
        "loss": 0.5818,
        "grad_norm": 26.651674270629883,
        "learning_rate": 9.305467595524595e-06,
        "epoch": 1.6043909647456196,
        "step": 7600
    },
    {
        "loss": 0.5663,
        "grad_norm": 36.455596923828125,
        "learning_rate": 9.164731545985505e-06,
        "epoch": 1.625501372176483,
        "step": 7700
    },
    {
        "loss": 0.5662,
        "grad_norm": 27.0660343170166,
        "learning_rate": 9.023995496446415e-06,
        "epoch": 1.6466117796073463,
        "step": 7800
    },
    {
        "loss": 0.5909,
        "grad_norm": 36.125762939453125,
        "learning_rate": 8.883259446907327e-06,
        "epoch": 1.6677221870382097,
        "step": 7900
    },
    {
        "loss": 0.6033,
        "grad_norm": 35.59330749511719,
        "learning_rate": 8.742523397368237e-06,
        "epoch": 1.6888325944690732,
        "step": 8000
    },
    {
        "loss": 0.5405,
        "grad_norm": 24.94896125793457,
        "learning_rate": 8.601787347829147e-06,
        "epoch": 1.7099430018999366,
        "step": 8100
    },
    {
        "loss": 0.5748,
        "grad_norm": 21.96120834350586,
        "learning_rate": 8.461051298290057e-06,
        "epoch": 1.7310534093308,
        "step": 8200
    },
    {
        "loss": 0.5642,
        "grad_norm": 26.105688095092773,
        "learning_rate": 8.32031524875097e-06,
        "epoch": 1.7521638167616636,
        "step": 8300
    },
    {
        "loss": 0.5648,
        "grad_norm": 40.669769287109375,
        "learning_rate": 8.17957919921188e-06,
        "epoch": 1.773274224192527,
        "step": 8400
    },
    {
        "loss": 0.5206,
        "grad_norm": 56.946651458740234,
        "learning_rate": 8.03884314967279e-06,
        "epoch": 1.7943846316233905,
        "step": 8500
    },
    {
        "loss": 0.534,
        "grad_norm": 27.473478317260742,
        "learning_rate": 7.8981071001337e-06,
        "epoch": 1.815495039054254,
        "step": 8600
    },
    {
        "loss": 0.5742,
        "grad_norm": 41.072410583496094,
        "learning_rate": 7.757371050594611e-06,
        "epoch": 1.8366054464851171,
        "step": 8700
    },
    {
        "loss": 0.5965,
        "grad_norm": 27.569292068481445,
        "learning_rate": 7.616635001055522e-06,
        "epoch": 1.8577158539159806,
        "step": 8800
    },
    {
        "loss": 0.508,
        "grad_norm": 43.26186752319336,
        "learning_rate": 7.475898951516432e-06,
        "epoch": 1.8788262613468438,
        "step": 8900
    },
    {
        "loss": 0.5612,
        "grad_norm": 35.24468231201172,
        "learning_rate": 7.335162901977342e-06,
        "epoch": 1.8999366687777073,
        "step": 9000
    },
    {
        "loss": 0.5152,
        "grad_norm": 25.56432342529297,
        "learning_rate": 7.194426852438252e-06,
        "epoch": 1.9210470762085707,
        "step": 9100
    },
    {
        "loss": 0.572,
        "grad_norm": 13.87940502166748,
        "learning_rate": 7.053690802899164e-06,
        "epoch": 1.9421574836394342,
        "step": 9200
    },
    {
        "loss": 0.5154,
        "grad_norm": 40.5422248840332,
        "learning_rate": 6.912954753360074e-06,
        "epoch": 1.9632678910702976,
        "step": 9300
    },
    {
        "loss": 0.5442,
        "grad_norm": 26.601306915283203,
        "learning_rate": 6.772218703820984e-06,
        "epoch": 1.984378298501161,
        "step": 9400
    },
    {
        "loss": 0.4762,
        "grad_norm": 31.491193771362305,
        "learning_rate": 6.631482654281894e-06,
        "epoch": 2.0054887059320246,
        "step": 9500
    },
    {
        "loss": 0.3855,
        "grad_norm": 25.006540298461914,
        "learning_rate": 6.490746604742806e-06,
        "epoch": 2.026599113362888,
        "step": 9600
    },
    {
        "loss": 0.4168,
        "grad_norm": 25.541584014892578,
        "learning_rate": 6.350010555203716e-06,
        "epoch": 2.0477095207937515,
        "step": 9700
    },
    {
        "loss": 0.4182,
        "grad_norm": 37.83918380737305,
        "learning_rate": 6.209274505664626e-06,
        "epoch": 2.068819928224615,
        "step": 9800
    },
    {
        "loss": 0.4626,
        "grad_norm": 36.628074645996094,
        "learning_rate": 6.068538456125536e-06,
        "epoch": 2.0899303356554784,
        "step": 9900
    },
    {
        "loss": 0.4223,
        "grad_norm": 26.548110961914062,
        "learning_rate": 5.927802406586448e-06,
        "epoch": 2.1110407430863414,
        "step": 10000
    },
    {
        "loss": 0.3684,
        "grad_norm": 21.249576568603516,
        "learning_rate": 5.787066357047358e-06,
        "epoch": 2.132151150517205,
        "step": 10100
    },
    {
        "loss": 0.3754,
        "grad_norm": 40.13148498535156,
        "learning_rate": 5.6463303075082685e-06,
        "epoch": 2.1532615579480683,
        "step": 10200
    },
    {
        "loss": 0.3607,
        "grad_norm": 50.26200866699219,
        "learning_rate": 5.5055942579691794e-06,
        "epoch": 2.1743719653789317,
        "step": 10300
    },
    {
        "loss": 0.3981,
        "grad_norm": 43.874263763427734,
        "learning_rate": 5.3648582084300896e-06,
        "epoch": 2.195482372809795,
        "step": 10400
    },
    {
        "loss": 0.4046,
        "grad_norm": 53.300018310546875,
        "learning_rate": 5.2241221588910005e-06,
        "epoch": 2.2165927802406586,
        "step": 10500
    },
    {
        "loss": 0.421,
        "grad_norm": 21.042129516601562,
        "learning_rate": 5.083386109351911e-06,
        "epoch": 2.237703187671522,
        "step": 10600
    },
    {
        "loss": 0.4292,
        "grad_norm": 35.70431137084961,
        "learning_rate": 4.942650059812822e-06,
        "epoch": 2.2588135951023856,
        "step": 10700
    },
    {
        "loss": 0.4115,
        "grad_norm": 24.642974853515625,
        "learning_rate": 4.801914010273732e-06,
        "epoch": 2.279924002533249,
        "step": 10800
    },
    {
        "loss": 0.3899,
        "grad_norm": 24.50594139099121,
        "learning_rate": 4.661177960734643e-06,
        "epoch": 2.3010344099641125,
        "step": 10900
    },
    {
        "loss": 0.4175,
        "grad_norm": 30.942974090576172,
        "learning_rate": 4.520441911195554e-06,
        "epoch": 2.322144817394976,
        "step": 11000
    },
    {
        "loss": 0.355,
        "grad_norm": 6.971529006958008,
        "learning_rate": 4.379705861656464e-06,
        "epoch": 2.343255224825839,
        "step": 11100
    },
    {
        "loss": 0.3971,
        "grad_norm": 18.167627334594727,
        "learning_rate": 4.238969812117375e-06,
        "epoch": 2.3643656322567024,
        "step": 11200
    },
    {
        "loss": 0.4188,
        "grad_norm": 20.5007381439209,
        "learning_rate": 4.098233762578285e-06,
        "epoch": 2.385476039687566,
        "step": 11300
    },
    {
        "loss": 0.3907,
        "grad_norm": 34.08584213256836,
        "learning_rate": 3.957497713039195e-06,
        "epoch": 2.4065864471184293,
        "step": 11400
    },
    {
        "loss": 0.411,
        "grad_norm": 56.491973876953125,
        "learning_rate": 3.816761663500106e-06,
        "epoch": 2.4276968545492927,
        "step": 11500
    },
    {
        "loss": 0.4332,
        "grad_norm": 39.36449432373047,
        "learning_rate": 3.676025613961016e-06,
        "epoch": 2.448807261980156,
        "step": 11600
    },
    {
        "loss": 0.3953,
        "grad_norm": 56.11875915527344,
        "learning_rate": 3.535289564421927e-06,
        "epoch": 2.4699176694110196,
        "step": 11700
    },
    {
        "loss": 0.4218,
        "grad_norm": 63.04047393798828,
        "learning_rate": 3.3945535148828372e-06,
        "epoch": 2.491028076841883,
        "step": 11800
    },
    {
        "loss": 0.4261,
        "grad_norm": 47.22783279418945,
        "learning_rate": 3.2538174653437482e-06,
        "epoch": 2.5121384842727466,
        "step": 11900
    },
    {
        "loss": 0.3587,
        "grad_norm": 38.984230041503906,
        "learning_rate": 3.1130814158046583e-06,
        "epoch": 2.53324889170361,
        "step": 12000
    },
    {
        "loss": 0.4105,
        "grad_norm": 42.440589904785156,
        "learning_rate": 2.9723453662655693e-06,
        "epoch": 2.5543592991344735,
        "step": 12100
    },
    {
        "loss": 0.3752,
        "grad_norm": 28.545255661010742,
        "learning_rate": 2.8316093167264794e-06,
        "epoch": 2.575469706565337,
        "step": 12200
    },
    {
        "loss": 0.3868,
        "grad_norm": 29.29892921447754,
        "learning_rate": 2.6908732671873904e-06,
        "epoch": 2.5965801139962004,
        "step": 12300
    },
    {
        "loss": 0.3673,
        "grad_norm": 34.08314895629883,
        "learning_rate": 2.550137217648301e-06,
        "epoch": 2.6176905214270634,
        "step": 12400
    },
    {
        "loss": 0.4171,
        "grad_norm": 33.499267578125,
        "learning_rate": 2.4094011681092115e-06,
        "epoch": 2.638800928857927,
        "step": 12500
    },
    {
        "loss": 0.421,
        "grad_norm": 38.203468322753906,
        "learning_rate": 2.268665118570122e-06,
        "epoch": 2.6599113362887903,
        "step": 12600
    },
    {
        "loss": 0.3364,
        "grad_norm": 9.15670108795166,
        "learning_rate": 2.1279290690310326e-06,
        "epoch": 2.6810217437196537,
        "step": 12700
    },
    {
        "loss": 0.3637,
        "grad_norm": 10.643087387084961,
        "learning_rate": 1.987193019491943e-06,
        "epoch": 2.702132151150517,
        "step": 12800
    },
    {
        "loss": 0.3485,
        "grad_norm": 11.998798370361328,
        "learning_rate": 1.8464569699528537e-06,
        "epoch": 2.7232425585813806,
        "step": 12900
    },
    {
        "loss": 0.3727,
        "grad_norm": 44.53166198730469,
        "learning_rate": 1.7057209204137643e-06,
        "epoch": 2.744352966012244,
        "step": 13000
    },
    {
        "loss": 0.4201,
        "grad_norm": 43.84321975708008,
        "learning_rate": 1.5649848708746746e-06,
        "epoch": 2.7654633734431076,
        "step": 13100
    },
    {
        "loss": 0.3739,
        "grad_norm": 30.090402603149414,
        "learning_rate": 1.4242488213355852e-06,
        "epoch": 2.786573780873971,
        "step": 13200
    },
    {
        "loss": 0.3641,
        "grad_norm": 19.310014724731445,
        "learning_rate": 1.2835127717964957e-06,
        "epoch": 2.807684188304834,
        "step": 13300
    },
    {
        "loss": 0.3765,
        "grad_norm": 39.89506149291992,
        "learning_rate": 1.1427767222574063e-06,
        "epoch": 2.8287945957356975,
        "step": 13400
    },
    {
        "loss": 0.3812,
        "grad_norm": 37.2579460144043,
        "learning_rate": 1.0020406727183168e-06,
        "epoch": 2.849905003166561,
        "step": 13500
    },
    {
        "loss": 0.338,
        "grad_norm": 36.232460021972656,
        "learning_rate": 8.613046231792275e-07,
        "epoch": 2.8710154105974244,
        "step": 13600
    },
    {
        "loss": 0.3472,
        "grad_norm": 30.35764503479004,
        "learning_rate": 7.20568573640138e-07,
        "epoch": 2.892125818028288,
        "step": 13700
    },
    {
        "loss": 0.3592,
        "grad_norm": 54.2016716003418,
        "learning_rate": 5.798325241010485e-07,
        "epoch": 2.9132362254591513,
        "step": 13800
    },
    {
        "loss": 0.4123,
        "grad_norm": 47.51285934448242,
        "learning_rate": 4.3909647456195906e-07,
        "epoch": 2.9343466328900147,
        "step": 13900
    },
    {
        "loss": 0.337,
        "grad_norm": 15.6547269821167,
        "learning_rate": 2.9836042502286966e-07,
        "epoch": 2.955457040320878,
        "step": 14000
    },
    {
        "loss": 0.3742,
        "grad_norm": 59.490989685058594,
        "learning_rate": 1.576243754837802e-07,
        "epoch": 2.9765674477517416,
        "step": 14100
    },
    {
        "loss": 0.3939,
        "grad_norm": 40.48653030395508,
        "learning_rate": 1.6888325944690734e-08,
        "epoch": 2.997677855182605,
        "step": 14200
    },
    {
        "train_runtime": 9287.4703,
        "train_samples_per_second": 24.481,
        "train_steps_per_second": 1.53,
        "total_flos": 2724339594783744.0,
        "train_loss": 0.6657129832571023,
        "epoch": 3.0,
        "step": 14211
    },
    {
        "eval_loss": 0.534479022026062,
        "eval_accuracy": 0.852749079681748,
        "eval_f1_macro": 0.7663109403348424,
        "eval_runtime": 352.7364,
        "eval_samples_per_second": 71.62,
        "eval_steps_per_second": 4.476,
        "epoch": 3.0,
        "step": 14211
    }
]